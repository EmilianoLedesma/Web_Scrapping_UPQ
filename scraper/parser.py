"""
M√≥dulo para parsear HTML del sistema UPQ.
Implementa parseo robusto que funciona incluso si cambian estilos CSS.
"""

from typing import Dict, List, Optional, Any
from bs4 import BeautifulSoup
import re
from datetime import datetime


class ParserError(Exception):
    """Error al parsear HTML."""
    pass


class UPQGradesParser:
    """
    Parser robusto para extraer calificaciones del HTML del sistema UPQ.
    No depende de clases CSS o IDs, solo de estructura sem√°ntica y contenido.
    """

    def __init__(self, html: str):
        """
        Inicializa el parser con HTML.

        Args:
            html: HTML de la p√°gina de calificaciones.
        """
        self.html = html
        self.soup = BeautifulSoup(html, 'html.parser')

    def parse_grades(self) -> Dict[str, Any]:
        """
        Parsea el HTML y extrae todas las calificaciones.

        Returns:
            Dict con estructura:
            {
                "alumno": str,
                "matricula": str,
                "periodo": str,
                "fecha_consulta": str (ISO format),
                "materias": List[Dict]
            }

        Raises:
            ParserError: Si no se puede parsear el HTML.
        """
        try:
            print("üîç Parseando HTML de calificaciones...")

            # Extraer informaci√≥n del alumno
            student_info = self._extract_student_info()

            # Extraer tabla de calificaciones
            grades_table = self._find_grades_table()

            if not grades_table:
                raise ParserError(
                    "No se encontr√≥ la tabla de calificaciones en el HTML"
                )

            # Parsear la tabla
            materias = self._parse_grades_table(grades_table)

            result = {
                "alumno": student_info.get("nombre", "No disponible"),
                "matricula": student_info.get("matricula", "No disponible"),
                "periodo": student_info.get("periodo", "No disponible"),
                "fecha_consulta": datetime.now().isoformat(),
                "materias": materias
            }

            print(f"‚úÖ Parseadas {len(materias)} materias exitosamente")

            return result

        except Exception as e:
            raise ParserError(f"Error al parsear calificaciones: {str(e)}")

    def _extract_student_info(self) -> Dict[str, str]:
        """
        Extrae informaci√≥n del alumno del HTML.

        Returns:
            Dict con nombre, matr√≠cula y periodo si est√°n disponibles.
        """
        info = {}

        # Buscar matr√≠cula con m√∫ltiples patrones
        for pattern in [
            r'Matr√≠cula:\s*(\d{8,9})',
            r'Matricula:\s*(\d{8,9})',
            r'MATR√çCULA:\s*(\d{8,9})',
            r'MATRICULA:\s*(\d{8,9})',
            r'Cuenta:\s*(\d{8,9})',
            r'No\.\s*Control:\s*(\d{8,9})',
            r'\b(\d{8,9})\b'  # Fallback: cualquier n√∫mero de 8-9 d√≠gitos
        ]:
            match = re.search(pattern, self.html, re.IGNORECASE)
            if match:
                info["matricula"] = match.group(1)
                break

        # Buscar nombre del alumno (puede estar en varios lugares)
        # Buscamos patrones comunes
        for pattern in [
            r'Bienvenido\s+([A-Z√Å√â√ç√ì√ö√ë\s]+)',  # Patr√≥n "Bienvenido NOMBRE"
            r'Alumno:\s*([A-Z√Å√â√ç√ì√ö√ë\s]+)',
            r'Nombre:\s*([A-Z√Å√â√ç√ì√ö√ë\s]+)',
            r'ALUMNO:\s*([A-Z√Å√â√ç√ì√ö√ë\s]+)',
            r'NOMBRE:\s*([A-Z√Å√â√ç√ì√ö√ë\s]+)',
            r'Estudiante:\s*([A-Z√Å√â√ç√ì√ö√ë\s]+)',
            # Buscar en elementos HTML espec√≠ficos
        ]:
            match = re.search(pattern, self.html, re.IGNORECASE)
            if match:
                nombre = match.group(1).strip()
                # Limpiar el nombre (remover m√∫ltiples espacios)
                nombre = re.sub(r'\s+', ' ', nombre)
                # Solo aceptar si tiene al menos 2 palabras (nombre y apellido)
                if len(nombre.split()) >= 2:
                    info["nombre"] = nombre
                    break
        
        # Si no encontramos con regex, buscar en elementos HTML
        if "nombre" not in info:
            # Buscar en divs, spans, h1-h6 que contengan "Bienvenido" o "Alumno"
            for tag in self.soup.find_all(['div', 'span', 'h1', 'h2', 'h3', 'h4', 'p']):
                text = tag.get_text(strip=True)
                if 'Bienvenido' in text or 'bienvenido' in text:
                    # Extraer el nombre despu√©s de "Bienvenido"
                    match = re.search(r'[Bb]ienvenido\s+([A-Z√Å√â√ç√ì√ö√ë\s]+)', text)
                    if match:
                        nombre = match.group(1).strip()
                        nombre = re.sub(r'\s+', ' ', nombre)
                        if len(nombre.split()) >= 2:
                            info["nombre"] = nombre
                            break

        # Buscar periodo acad√©mico
        for pattern in [
            r'Periodo:\s*([A-Z\s\-\d]+)',
            r'PERIODO:\s*([A-Z\s\-\d]+)',
            r'(ENERO-ABRIL|MAYO-AGOSTO|SEPTIEMBRE-DICIEMBRE)\s*\d{4}'
        ]:
            match = re.search(pattern, self.html)
            if match:
                info["periodo"] = match.group(1).strip()
                break

        return info

    def _find_grades_table(self) -> Optional[Any]:
        """
        Encuentra la tabla de calificaciones en el HTML.
        Busca de forma robusta sin depender de IDs o clases.

        Returns:
            Tag de BeautifulSoup con la tabla, o None si no se encuentra.
        """
        # Estrategia 1: Buscar tabla con headers que contengan palabras clave
        tables = self.soup.find_all('table')

        for table in tables:
            # Buscar headers en la tabla
            headers = table.find_all('th')
            header_texts = [th.get_text(strip=True).lower() for th in headers]

            # Si contiene palabras clave relacionadas con calificaciones
            keywords = ['materia', 'calificaci√≥n', 'parcial', 'p1', 'p2', 'p3', 'grupo', 'profesor']
            if any(keyword in ' '.join(header_texts) for keyword in keywords):
                return table

        # Estrategia 2: Buscar la tabla m√°s grande con <td> y <tr>
        if tables:
            largest_table = max(tables, key=lambda t: len(t.find_all('tr')))
            if len(largest_table.find_all('tr')) > 1:
                return largest_table

        return None

    def _parse_grades_table(self, table: Any) -> List[Dict[str, Any]]:
        """
        Parsea la tabla de calificaciones.

        Args:
            table: Tag de BeautifulSoup con la tabla.

        Returns:
            Lista de diccionarios con informaci√≥n de cada materia.
        """
        materias = []

        # Extraer headers - buscar la fila de headers real (sin colspan)
        # El sistema UPQ tiene 2 filas de headers: una de agrupaci√≥n y una real
        thead = table.find('thead')
        header_row = None

        if thead:
            # Buscar todas las filas de headers
            header_rows = thead.find_all('tr')
            # Usar la √∫ltima fila (que tiene los headers detallados sin colspan)
            for row in reversed(header_rows):
                headers = row.find_all('th')
                # Verificar que no todos los headers tengan colspan
                has_colspan = any(h.get('colspan') for h in headers)
                if not has_colspan or len(headers) > 5:
                    header_row = row
                    break

        if not header_row:
            # Fallback: buscar cualquier fila con <th>
            header_row = table.find('tr')

        headers = header_row.find_all('th') if header_row else []
        if not headers:
            headers = header_row.find_all(['th', 'td']) if header_row else []

        header_texts = [h.get_text(strip=True) for h in headers]

        # Mapear √≠ndices de columnas importantes
        column_map = self._map_columns(header_texts)

        # Extraer filas de datos
        rows = table.find_all('tr')

        for row in rows:
            cells = row.find_all('td')

            # Saltar filas sin suficientes celdas (m√≠nimo 2: materia + algo)
            if len(cells) < 2:
                continue

            # Extraer datos de la materia
            materia = self._extract_materia_data(cells, column_map)

            if materia and materia.get('nombre'):
                materias.append(materia)

        return materias

    def _map_columns(self, headers: List[str]) -> Dict[str, int]:
        """
        Mapea los nombres de columnas a sus √≠ndices.
        Hace matching flexible por contenido, no por nombres exactos.

        Args:
            headers: Lista de nombres de headers.

        Returns:
            Diccionario mapeando tipo de columna a √≠ndice.
        """
        column_map = {}

        for i, header in enumerate(headers):
            header_lower = header.lower()

            # Materia / Asignatura
            if any(word in header_lower for word in ['materia', 'asignatura', 'curso']):
                column_map['materia'] = i

            # Clave
            elif any(word in header_lower for word in ['clave', 'c√≥digo', 'codigo']):
                column_map['clave'] = i

            # Aula
            elif any(word in header_lower for word in ['aula', 'sal√≥n', 'salon']):
                column_map['aula'] = i

            # Grupo
            elif any(word in header_lower for word in ['grupo', 'secci√≥n', 'seccion']):
                column_map['grupo'] = i

            # Profesor
            elif any(word in header_lower for word in ['profesor', 'docente', 'maestro']):
                column_map['profesor'] = i

            # Calificaciones por parcial (P1, P2, P3, etc.)
            elif re.search(r'p[1-9]|pf[1-9]|primer|segundo|tercer|parcial', header_lower):
                # Detectar n√∫mero de parcial
                parcial_num = self._extract_parcial_number(header_lower)
                if parcial_num:
                    # Detectar si es parcial final (PF)
                    if 'pf' in header_lower or 'final del' in header_lower:
                        column_map[f'PF{parcial_num}'] = i
                    else:
                        column_map[f'P{parcial_num}'] = i

            # Calificaci√≥n Final (promedio final)
            elif 'final' in header_lower and 'calificaci√≥n' in header_lower:
                column_map['calificacion_final'] = i

        return column_map

    def _extract_parcial_number(self, text: str) -> Optional[int]:
        """
        Extrae el n√∫mero de parcial de un texto.

        Args:
            text: Texto del header.

        Returns:
            N√∫mero de parcial (1, 2, 3, etc.) o None.
        """
        # Buscar P1, P2, P3, etc.
        match = re.search(r'p(\d)', text.lower())
        if match:
            return int(match.group(1))

        # Buscar "primer", "segundo", "tercer"
        ordinals = {
            'primer': 1, 'segundo': 2, 'tercer': 3,
            'cuarto': 4, 'quinto': 5, 'sexto': 6
        }
        for word, num in ordinals.items():
            if word in text.lower():
                return num

        return None

    def _extract_materia_data(
        self,
        cells: List[Any],
        column_map: Dict[str, int]
    ) -> Optional[Dict[str, Any]]:
        """
        Extrae datos de una materia desde las celdas de una fila.

        Args:
            cells: Lista de celdas (<td>) de la fila.
            column_map: Mapeo de columnas a √≠ndices.

        Returns:
            Diccionario con datos de la materia o None si no es v√°lido.
        """
        try:
            # Obtener valor de celda de forma segura
            def get_cell_value(col_name: str) -> Optional[str]:
                if col_name in column_map and column_map[col_name] < len(cells):
                    value = cells[column_map[col_name]].get_text(strip=True)
                    return value if value else None
                return None

            # Extraer nombre de materia (campo obligatorio)
            nombre = get_cell_value('materia')
            if not nombre or len(nombre) < 3:
                return None

            # Extraer calificaciones parciales (P1, P2, P3)
            calificaciones = {}
            for i in range(1, 10):  # Buscar hasta P9
                parcial = f'P{i}'
                if parcial in column_map:
                    valor = get_cell_value(parcial)
                    if valor:
                        # Intentar convertir a float
                        try:
                            calificaciones[parcial] = float(valor)
                        except ValueError:
                            # Si no es n√∫mero, dejarlo como None
                            calificaciones[parcial] = None
                    else:
                        calificaciones[parcial] = None

            # Extraer calificaciones finales de parciales (PF1, PF2, PF3)
            calificaciones_finales = {}
            for i in range(1, 10):
                parcial_final = f'PF{i}'
                if parcial_final in column_map:
                    valor = get_cell_value(parcial_final)
                    if valor:
                        try:
                            calificaciones_finales[parcial_final] = float(valor)
                        except ValueError:
                            calificaciones_finales[parcial_final] = None
                    else:
                        calificaciones_finales[parcial_final] = None

            # Extraer calificaci√≥n final de la materia
            calif_final = get_cell_value('calificacion_final')
            calif_final_valor = None
            if calif_final:
                try:
                    calif_final_valor = float(calif_final)
                except ValueError:
                    pass

            materia_data = {
                "nombre": nombre,
                "clave": get_cell_value('clave'),
                "aula": get_cell_value('aula'),
                "grupo": get_cell_value('grupo'),
                "profesor": get_cell_value('profesor'),
                "calificaciones": calificaciones,
                "calificaciones_finales": calificaciones_finales if calificaciones_finales else None,
                "calificacion_final": calif_final_valor
            }

            return materia_data

        except Exception as e:
            print(f"‚ö†Ô∏è  Error al parsear fila: {str(e)}")
            return None

    def get_raw_html(self) -> str:
        """Retorna el HTML original."""
        return self.html

    def save_html_debug(self, filepath: str) -> None:
        """
        Guarda el HTML para debugging.

        Args:
            filepath: Ruta donde guardar el HTML.
        """
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(self.html)
        print(f"üíæ HTML guardado para debugging en: {filepath}")


def parse_kardex(html: str) -> List[Dict[str, str]]:
    """
    Parsea el kardex acad√©mico desde el HTML de la p√°gina de calificaciones.
    
    El kardex contiene el historial completo de materias cursadas con:
    n√∫mero, clave, nombre, cuatrimestre, calificaci√≥n y tipo de evaluaci√≥n.
    
    Args:
        html: HTML de la p√°gina de calificaciones con kardex
        
    Returns:
        Lista de diccionarios con datos de cada materia del kardex
        
    Ejemplo de retorno:
        [
            {
                'numero': '1',
                'clave': '',
                'materia': '√ÅLGEBRA LINEAL',
                'cuatrimestre': '1',
                'calificacion': '8',
                'tipo_evaluacion': 'CURSO ORDINARIO'
            },
            ...
        ]
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Buscar el div o secci√≥n que contiene "Kardex"
    kardex_section = None
    
    # Buscar en los tabs
    for div in soup.find_all('div'):
        title_attr = div.get('title', '')
        if 'kardex' in title_attr.lower():
            kardex_section = div
            break
    
    if not kardex_section:
        print("‚ö†Ô∏è  No se encontr√≥ la secci√≥n de Kardex en el HTML")
        return []
    
    # Encontrar la tabla dentro de la secci√≥n kardex
    table = kardex_section.find('table', class_='grid')
    if not table:
        print("‚ö†Ô∏è  No se encontr√≥ tabla en la secci√≥n de Kardex")
        return []
    
    materias = []
    for row in table.find_all('tr', class_=['row0', 'row1']):
        cells = row.find_all('td')
        if len(cells) >= 6:
            materia = {
                'numero': cells[0].text.strip(),
                'clave': cells[1].text.strip(),
                'materia': cells[2].text.strip(),
                'cuatrimestre': cells[3].text.strip(),
                'calificacion': cells[4].text.strip(),
                'tipo_evaluacion': cells[5].text.strip()
            }
            materias.append(materia)
    
    print(f"‚úÖ Kardex parseado: {len(materias)} materias encontradas")
    return materias


def parse_student_profile(html: str) -> Dict[str, str]:
    """
    Parsea el perfil del estudiante desde el HTML del home.
    
    Extrae todos los datos del perfil: nombre, matr√≠cula, carrera, promedio,
    cr√©ditos, nivel de ingl√©s, tutor, etc.
    
    Args:
        html: HTML de la p√°gina home
        
    Returns:
        Diccionario con datos del perfil
        
    Ejemplo de retorno:
        {
            'nombre': 'EMILIANO LEDESMA LEDESMA',
            'matricula': '123046244',
            'carrera': 'SISTEMAS',
            'generacion': '20',
            'grupo': 'S204',
            'ultimo_cuatrimestre': '7',
            'promedio_general': '9.07',
            'materias_aprobadas': '45',
            'creditos': '258/360',
            'materias_no_acreditadas': '0',
            'nivel_ingles': '9',
            'estatus': 'ACTIVO',
            'nss': '49160134976',
            'tutor': 'ALVARADO SALAYANDIA CECILIA',
            'email_tutor': 'cecilia.alvarado@upq.edu.mx',
            'foto_url': '/uploads/fotos/alumnos/20/123046244.jpg'
        }
    """
    soup = BeautifulSoup(html, 'html.parser')
    perfil = {}
    
    # Buscar todos los elementos <strong> que contienen etiquetas de campos
    for strong in soup.find_all('strong'):
        campo_text = strong.text.strip()
        
        # Remover : y espacios, convertir a min√∫sculas y _ para uniformidad
        campo = campo_text.replace(':', '').strip().lower().replace(' ', '_')
        
        # Obtener el valor que est√° despu√©s del <strong>
        valor = ''
        next_sibling = strong.next_sibling
        
        if next_sibling:
            if isinstance(next_sibling, str):
                valor = next_sibling.strip()
            else:
                valor = next_sibling.text.strip() if hasattr(next_sibling, 'text') else ''
        
        if valor:
            perfil[campo] = valor
    
    # Extraer foto si existe
    foto_img = soup.find('img', src=re.compile(r'/uploads/fotos/alumnos/'))
    if foto_img:
        perfil['foto_url'] = foto_img['src']
    
    # Extraer nombre de usuario del header
    username_div = soup.find('div', class_='username')
    if username_div:
        username_span = username_div.find('span', style=re.compile(r'font-weight:bold'))
        if username_span:
            perfil['nombre_usuario'] = username_span.text.strip()
    
    print(f"‚úÖ Perfil parseado: {len(perfil)} campos encontrados")
    return perfil


def parse_carga_academica(html: str) -> Dict:
    """
    Parsea la carga acad√©mica actual del estudiante.
    
    Extrae las materias del cuatrimestre en curso con informaci√≥n de:
    aula, grupo, profesor, calificaciones parciales y finales.
    
    Args:
        html: HTML de la p√°gina de carga acad√©mica
        
    Returns:
        Diccionario con periodo y lista de materias
        
    Ejemplo de retorno:
        {
            'periodo': 'CARGA ACAD√âMICA: SEPTIEMBRE-DICIEMBRE 2025',
            'materias': [
                {
                    'numero': '1',
                    'clave': '',
                    'materia': 'LIDERAZGO DE EQUIPOS DE ALTO DESEMPE√ëO',
                    'aula': 'C104',
                    'grupo': 'S204-7',
                    'profesor': 'RAMIREZ RESENDIZ ADRIANA KARINA',
                    'parciales': {'p1': '9.35', 'p2': '', 'p3': ''},
                    'finales': {'pf1': '', 'pf2': '', 'pf3': ''},
                    'calificacion_final': ''
                },
                ...
            ]
        }
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Extraer t√≠tulo del periodo
    titulo_h4 = soup.find('h4', class_='title')
    periodo = titulo_h4.text.strip() if titulo_h4 else "Periodo actual"
    
    # Extraer tabla
    table = soup.find('table', id='tblMaterias')
    if not table:
        return {'periodo': periodo, 'materias': []}
    
    materias = []
    for row in table.find_all('tr', class_=['row0', 'row1']):
        cells = row.find_all('td')
        if len(cells) >= 13:
            materia = {
                'numero': cells[0].text.strip(),
                'clave': cells[1].text.strip(),
                'materia': cells[2].text.strip(),
                'aula': cells[3].text.strip(),
                'grupo': cells[4].text.strip(),
                'profesor': cells[5].text.strip(),
                'parciales': {
                    'p1': cells[6].text.strip(),
                    'p2': cells[7].text.strip(),
                    'p3': cells[8].text.strip(),
                },
                'finales': {
                    'pf1': cells[9].text.strip(),
                    'pf2': cells[10].text.strip(),
                    'pf3': cells[11].text.strip(),
                },
                'calificacion_final': cells[12].text.strip()
            }
            materias.append(materia)
    
    print(f"‚úÖ Carga acad√©mica parseada: {len(materias)} materias encontradas")
    return {
        'periodo': periodo,
        'materias': materias
    }


def parse_historial_academico(html: str) -> List[Dict]:
    """
    Parsea el historial acad√©mico completo del estudiante.
    
    Extrae todas las materias cursadas con fecha, ciclo, cr√©ditos,
    calificaci√≥n, tipo de evaluaci√≥n y estado.
    
    Args:
        html: HTML de la p√°gina de historial acad√©mico
        
    Returns:
        Lista de diccionarios con datos de cada materia
        
    Ejemplo de retorno:
        [
            {
                'numero': '1',
                'fecha': '15/08/2025',
                'ciclo': 'MAYO - AGOSTO 2025',
                'clave': '',
                'materia': 'ADMINISTRACI√ìN DE BASE DE DATOS',
                'creditos': '7',
                'calificacion': '9',
                'tipo_evaluacion': 'CURSO ORDINARIO',
                'tipo_evaluacion_codigo': '1',
                'estado': ''
            },
            ...
        ]
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Buscar la tabla principal del historial
    table = soup.find('table', class_='grid')
    if not table:
        print("‚ö†Ô∏è  No se encontr√≥ tabla de historial acad√©mico")
        return []
    
    historial = []
    for row in table.find_all('tr', class_=['row0', 'row1']):
        cells = row.find_all('td')
        if len(cells) >= 9:
            # Extraer tipo de evaluaci√≥n del atributo title
            tipo_eval_td = cells[7]
            tipo_eval_titulo = tipo_eval_td.get('title', tipo_eval_td.text.strip())
            tipo_eval_codigo = tipo_eval_td.text.strip()
            
            materia = {
                'numero': cells[0].text.strip(),
                'fecha': cells[1].text.strip(),
                'ciclo': cells[2].text.strip(),
                'clave': cells[3].text.strip(),
                'materia': cells[4].text.strip(),
                'creditos': cells[5].text.strip(),
                'calificacion': cells[6].text.strip(),
                'tipo_evaluacion': tipo_eval_titulo,
                'tipo_evaluacion_codigo': tipo_eval_codigo,
                'estado': cells[8].text.strip()
            }
            historial.append(materia)
    
    print(f"‚úÖ Historial acad√©mico parseado: {len(historial)} registros encontrados")
    return historial


def parse_mapa_curricular(html: str) -> Dict[str, List[Dict]]:
    """
    Parsea el mapa curricular completo de la carrera.
    
    Extrae el plan de estudios completo organizado por ciclos de formaci√≥n
    y cuatrimestres, mostrando todas las materias con calificaciones,
    tipo de evaluaci√≥n e intentos.
    
    Args:
        html: HTML de la p√°gina de informaci√≥n general del alumno
        
    Returns:
        Diccionario con cuatrimestres como keys y listas de materias como values
        
    Ejemplo de retorno:
        {
            '1er. Cuatrimestre': [
                {
                    'numero': '1',
                    'materia': 'INGL√âS I',
                    'calificacion': '10',
                    'tipo_evaluacion': '11',
                    'intentos': '1',
                    'acreditada': True
                },
                ...
            ],
            '2do. Cuatrimestre': [...],
            ...
        }
    """
    soup = BeautifulSoup(html, 'html.parser')
    mapa = {}
    
    # Encontrar todos los fieldsets (ciclos de formaci√≥n)
    for fieldset in soup.find_all('fieldset'):
        legend = fieldset.find('legend')
        if not legend:
            continue
            
        ciclo_nombre = legend.text.strip()
        
        # Encontrar todas las tablas de cuatrimestres dentro del ciclo
        for table in fieldset.find_all('table', class_='grid'):
            # Obtener el nombre del cuatrimestre del header
            header = table.find('thead')
            if not header:
                continue
                
            th = header.find('th', attrs={'colspan': True})
            if not th:
                continue
                
            cuatrimestre = th.text.strip()
            
            materias = []
            for row in table.find_all('tr', class_=['row0', 'row1']):
                # Verificar si la materia est√° acreditada
                acreditada = 'acreditado' in row.get('class', [])
                
                cells = row.find_all('td')
                if len(cells) >= 5:
                    materia = {
                        'numero': cells[0].text.strip(),
                        'materia': cells[1].text.strip(),
                        'calificacion': cells[2].text.strip(),
                        'tipo_evaluacion': cells[3].text.strip(),
                        'intentos': cells[4].text.strip(),
                        'acreditada': acreditada
                    }
                    materias.append(materia)
            
            if materias:
                mapa[cuatrimestre] = materias
    
    print(f"‚úÖ Mapa curricular parseado: {len(mapa)} cuatrimestres encontrados")
    return mapa


def parse_horario(html: str) -> List[Dict]:
    """
    Parsea el horario semanal de clases.
    
    Extrae el horario completo con d√≠a, horas, aula, materia y profesor.
    
    Args:
        html: HTML de la p√°gina de horario de materias
        
    Returns:
        Lista de diccionarios con datos de cada clase
        
    Ejemplo de retorno:
        [
            {
                'dia': 'LUNES',
                'hora_inicio': '08:00:00',
                'hora_fin': '10:00:00',
                'aula': 'C104',
                'materia': 'PROGRAMACI√ìN WEB',
                'profesor': 'MOYA MOYA JOSE JAVIER'
            },
            ...
        ]
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Buscar la tabla del horario
    table = soup.find('table', class_='grid')
    if not table:
        print("‚ö†Ô∏è  No se encontr√≥ tabla de horario")
        return []
    
    horario = []
    for row in table.find_all('tr', class_=['row0', 'row1']):
        cells = row.find_all('td')
        if len(cells) >= 6:
            clase = {
                'dia': cells[0].text.strip(),
                'hora_inicio': cells[1].text.strip(),
                'hora_fin': cells[2].text.strip(),
                'aula': cells[3].text.strip(),
                'materia': cells[4].text.strip(),
                'profesor': cells[5].text.strip()
            }
            horario.append(clase)
    
    print(f"‚úÖ Horario parseado: {len(horario)} clases encontradas")
    return horario


def parse_boleta(html: str) -> Dict[str, Any]:
    """
    Parsea la boleta de calificaciones.
    
    Extrae calificaciones organizadas por cuatrimestre con promedios.
    
    Args:
        html: HTML de la p√°gina de boleta de calificaciones
        
    Returns:
        Diccionario con cuatrimestres y sus materias
        
    Ejemplo de retorno:
        {
            'cuatrimestres': [
                {
                    'numero': '7',
                    'nombre': 'S√âPTIMO CUATRIMESTRE',
                    'promedio': '9.14',
                    'creditos': '34',
                    'materias': [
                        {
                            'materia': 'BASE DE DATOS',
                            'calificacion': '8',
                            'creditos': '8'
                        },
                        ...
                    ]
                },
                ...
            ]
        }
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    cuatrimestres = []
    
    # Buscar todas las tablas de cuatrimestres
    for table in soup.find_all('table', class_='grid'):
        # Buscar el header del cuatrimestre
        header = table.find('thead')
        if not header:
            continue
            
        th = header.find('th', attrs={'colspan': True})
        if not th:
            continue
            
        nombre_cuatri = th.text.strip()
        
        # Extraer n√∫mero de cuatrimestre si est√° en el nombre
        numero_match = re.search(r'(\d+)', nombre_cuatri)
        numero = numero_match.group(1) if numero_match else '0'
        
        materias = []
        promedio = ''
        creditos = ''
        
        for row in table.find_all('tr', class_=['row0', 'row1']):
            cells = row.find_all('td')
            if len(cells) >= 3:
                # Verificar si es la fila de promedio
                if 'promedio' in cells[0].text.lower():
                    promedio = cells[1].text.strip()
                    creditos = cells[2].text.strip() if len(cells) > 2 else ''
                else:
                    materia = {
                        'materia': cells[0].text.strip(),
                        'calificacion': cells[1].text.strip(),
                        'creditos': cells[2].text.strip() if len(cells) > 2 else ''
                    }
                    materias.append(materia)
        
        if materias:
            cuatrimestres.append({
                'numero': numero,
                'nombre': nombre_cuatri,
                'promedio': promedio,
                'creditos': creditos,
                'materias': materias
            })
    
    print(f"‚úÖ Boleta parseada: {len(cuatrimestres)} cuatrimestres encontrados")
    return {'cuatrimestres': cuatrimestres}


def parse_pagos(html: str) -> List[Dict]:
    """
    Parsea el historial de pagos.
    
    Extrae todos los pagos realizados con fecha, folio, concepto y monto.
    
    Args:
        html: HTML de la p√°gina de pagos
        
    Returns:
        Lista de diccionarios con datos de cada pago
        
    Ejemplo de retorno:
        [
            {
                'fecha': '15/08/2025',
                'folio': 'F123456',
                'concepto': 'COLEGIATURA SEPTIEMBRE',
                'monto': '$2,500.00',
                'forma_pago': 'TRANSFERENCIA'
            },
            ...
        ]
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Buscar la tabla de pagos
    table = soup.find('table', class_='grid')
    if not table:
        print("‚ö†Ô∏è  No se encontr√≥ tabla de pagos")
        return []
    
    pagos = []
    for row in table.find_all('tr', class_=['row0', 'row1']):
        cells = row.find_all('td')
        if len(cells) >= 5:
            pago = {
                'fecha': cells[0].text.strip(),
                'folio': cells[1].text.strip(),
                'concepto': cells[2].text.strip(),
                'monto': cells[3].text.strip(),
                'forma_pago': cells[4].text.strip()
            }
            pagos.append(pago)
    
    print(f"‚úÖ Pagos parseados: {len(pagos)} registros encontrados")
    return pagos


def parse_adeudos(html: str) -> List[Dict]:
    """
    Parsea los adeudos pendientes.
    
    Extrae adeudos con concepto, monto y fecha l√≠mite.
    
    Args:
        html: HTML de la p√°gina de adeudos
        
    Returns:
        Lista de diccionarios con datos de cada adeudo
        
    Ejemplo de retorno:
        [
            {
                'concepto': 'COLEGIATURA OCTUBRE',
                'monto': '$2,500.00',
                'fecha_limite': '31/10/2025',
                'estado': 'PENDIENTE'
            },
            ...
        ]
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Buscar la tabla de adeudos
    table = soup.find('table', class_='grid')
    if not table:
        print("‚ö†Ô∏è  No se encontr√≥ tabla de adeudos")
        return []
    
    adeudos = []
    for row in table.find_all('tr', class_=['row0', 'row1']):
        cells = row.find_all('td')
        
        # Verificar si es el mensaje de "No se encontraron registros"
        if len(cells) == 1 or 'no se encontraron' in cells[0].text.lower():
            continue
            
        if len(cells) >= 3:
            adeudo = {
                'concepto': cells[0].text.strip(),
                'monto': cells[1].text.strip(),
                'fecha_limite': cells[2].text.strip() if len(cells) > 2 else '',
                'estado': cells[3].text.strip() if len(cells) > 3 else 'PENDIENTE'
            }
            adeudos.append(adeudo)
    
    print(f"‚úÖ Adeudos parseados: {len(adeudos)} registros encontrados")
    return adeudos


def parse_documentos(html: str) -> List[Dict]:
    """
    Parsea los documentos en proceso.
    
    Extrae documentos solicitados con folio, tipo, fecha y estado.
    
    Args:
        html: HTML de la p√°gina de documentos en proceso
        
    Returns:
        Lista de diccionarios con datos de cada documento
        
    Ejemplo de retorno:
        [
            {
                'folio': 'DOC-12345',
                'documento': 'CONSTANCIA DE ESTUDIOS',
                'fecha_solicitud': '01/09/2025',
                'estado': 'EN PROCESO',
                'fecha_entrega': '05/09/2025'
            },
            ...
        ]
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Buscar la tabla de documentos
    table = soup.find('table', class_='grid')
    if not table:
        print("‚ö†Ô∏è  No se encontr√≥ tabla de documentos")
        return []
    
    documentos = []
    for row in table.find_all('tr', class_=['row0', 'row1']):
        cells = row.find_all('td')
        
        # Verificar si es el mensaje de "No se encontraron registros"
        if len(cells) == 1 or 'no se encontraron' in cells[0].text.lower():
            continue
            
        if len(cells) >= 4:
            documento = {
                'folio': cells[0].text.strip(),
                'documento': cells[1].text.strip(),
                'fecha_solicitud': cells[2].text.strip(),
                'estado': cells[3].text.strip(),
                'fecha_entrega': cells[4].text.strip() if len(cells) > 4 else ''
            }
            documentos.append(documento)
    
    print(f"‚úÖ Documentos parseados: {len(documentos)} registros encontrados")
    return documentos


def parse_seguimiento_cuatrimestral(html: str) -> List[Dict]:
    """
    Parsea el seguimiento cuatrimestral (calendario acad√©mico).
    
    Extrae informaci√≥n de progreso por cuatrimestre con promedios y cr√©ditos.
    
    Args:
        html: HTML de la p√°gina de seguimiento cuatrimestral
        
    Returns:
        Lista de diccionarios con datos de cada cuatrimestre
        
    Ejemplo de retorno:
        [
            {
                'cuatrimestre': '1',
                'nombre': 'PRIMER CUATRIMESTRE',
                'periodo': 'SEPTIEMBRE - DICIEMBRE 2020',
                'promedio': '9.14',
                'creditos': '48',
                'creditos_acumulados': '48',
                'estado': 'CONCLUIDO'
            },
            ...
        ]
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Buscar la tabla de seguimiento
    table = soup.find('table', class_='grid')
    if not table:
        print("‚ö†Ô∏è  No se encontr√≥ tabla de seguimiento cuatrimestral")
        return []
    
    seguimiento = []
    for row in table.find_all('tr', class_=['row0', 'row1']):
        cells = row.find_all('td')
        if len(cells) >= 6:
            cuatri = {
                'cuatrimestre': cells[0].text.strip(),
                'nombre': cells[1].text.strip(),
                'periodo': cells[2].text.strip(),
                'promedio': cells[3].text.strip(),
                'creditos': cells[4].text.strip(),
                'creditos_acumulados': cells[5].text.strip(),
                'estado': cells[6].text.strip() if len(cells) > 6 else ''
            }
            seguimiento.append(cuatri)
    
    print(f"‚úÖ Seguimiento parseado: {len(seguimiento)} cuatrimestres encontrados")
    return seguimiento


def parse_estancias(html: str) -> List[Dict]:
    """
    Parsea las estancias profesionales y estad√≠a del estudiante.
    
    Extrae informaci√≥n completa de estancias I, II y estad√≠a profesional
    desde la secci√≥n "Estancias y Estad√≠a" del endpoint de informaci√≥n general.
    
    Args:
        html: HTML de la p√°gina de informaci√≥n general (alumno_informacion_general)
        
    Returns:
        Lista de diccionarios con datos de cada estancia/estad√≠a
        
    Ejemplo de retorno:
        [
            {
                'numero': '1',
                'curso': 'Estancia I',
                'empresa': 'UNIVERSIDAD POLITECNICA DE QUERETARO',
                'descripcion': 'Este curso ofrece conocimientos...',
                'periodo': 'ENERO - ABRIL 2025',
                'estatus': 'CONCLUIDO'
            },
            {
                'numero': '2',
                'curso': 'Estancia II',
                'empresa': 'SECRETARIA DE EDUCACION DEL ESTADO DE QUERETARO',
                'descripcion': 'Obtencion de estadistica educativa...',
                'periodo': 'SEPTIEMBRE-DICIEMBRE 2025',
                'estatus': 'AUTORIZADO'
            }
        ]
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Buscar la secci√≥n de estancias
    estancias_section = None
    for fieldset in soup.find_all('fieldset'):
        legend = fieldset.find('legend')
        if legend and 'Estancias y Estad' in legend.text:
            estancias_section = fieldset
            break
    
    if not estancias_section:
        print("‚ö†Ô∏è  No se encontr√≥ secci√≥n de estancias")
        return []
    
    # Buscar la tabla dentro de la secci√≥n
    table = estancias_section.find('table', class_='grid')
    if not table:
        print("‚ö†Ô∏è  No se encontr√≥ tabla de estancias")
        return []
    
    estancias = []
    for row in table.find_all('tr', class_=['row0', 'row1']):
        cells = row.find_all('td')
        if len(cells) >= 6:
            estancia = {
                'numero': cells[0].text.strip(),
                'curso': cells[1].text.strip(),
                'empresa': cells[2].text.strip(),
                'descripcion': cells[3].text.strip(),
                'periodo': cells[4].text.strip(),
                'estatus': cells[5].text.strip()
            }
            estancias.append(estancia)
    
    print(f"‚úÖ Estancias parseadas: {len(estancias)} registros encontrados")
    return estancias


def parse_servicio_social(html: str) -> Dict[str, Any]:
    """
    Parsea el estatus del servicio social del estudiante.
    
    Extrae informaci√≥n del servicio social desde la secci√≥n correspondiente
    del endpoint de informaci√≥n general.
    
    Args:
        html: HTML de la p√°gina de informaci√≥n general (alumno_informacion_general)
        
    Returns:
        Diccionario con datos del servicio social
        
    Ejemplo de retorno:
        {
            'activo': False,
            'materias_requeridas': '45',
            'materias_faltantes': '0',
            'estatus': 'PUEDE REALIZAR SERVICIO SOCIAL',
            'cumple_requisitos': True
        }
    """
    soup = BeautifulSoup(html, 'html.parser')
    
    # Buscar la secci√≥n de servicio social
    servicio_section = None
    for fieldset in soup.find_all('fieldset'):
        legend = fieldset.find('legend')
        if legend and 'Servicio Social' in legend.text:
            servicio_section = fieldset
            break
    
    if not servicio_section:
        print("‚ö†Ô∏è  No se encontr√≥ secci√≥n de servicio social")
        return {}
    
    # Buscar la tabla dentro de la secci√≥n
    table = servicio_section.find('table', class_='grid')
    if not table:
        print("‚ö†Ô∏è  No se encontr√≥ tabla de servicio social")
        return {}
    
    servicio = {}
    rows = table.find_all('tr')
    
    for row in rows:
        cells = row.find_all('td')
        if len(cells) >= 2:
            key = cells[0].text.strip().rstrip(':')
            value = cells[1].text.strip()
            
            if 'Servicio Social' in key:
                servicio['activo'] = value.upper() == 'SI'
            elif 'Materias Requeridas' in key:
                servicio['materias_requeridas'] = value
            elif 'Materias Faltantes' in key:
                servicio['materias_faltantes'] = value
            elif 'Estatus Servicio Social' in key:
                servicio['estatus'] = value
    
    # Determinar si cumple requisitos
    if servicio.get('materias_faltantes'):
        servicio['cumple_requisitos'] = servicio['materias_faltantes'] == '0'
    
    print(f"‚úÖ Servicio social parseado: {servicio}")
    return servicio

